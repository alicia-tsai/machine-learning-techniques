{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Foundation & Techniques: Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy Targets\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Consider the bin model for a hypothesis $h$ that makes an error with probability $\\mu$ in approximating a deterministic target function $f$ (both $h$ and $f$ outputs $\\{-1, +1\\}$). If we use the same $h$ to approximate a noisy version of $f$ given by\n",
    "\n",
    "$$P(x, y) = P(x)P(y|x)$$\n",
    "\n",
    "$$\n",
    "P(y|x)= \\begin{cases}\n",
    "    \\lambda & \\text{y = f(x)}\\\\\n",
    "    1-\\lambda & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "#### What is the probability of error that $h$ makes in approximating the noisy target $y$ ? Please provide explanation of your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original error is $\\mu$, after giving the noise by flipping the label (1 $\\rightarrow$ -1 and -1 $\\rightarrow$ 1), the new error will be the original error $\\mu$ times the probability to stay at the same condition (probability to still makes error) and the error from the correct part, $1 - \\mu$ that is now incorrect; that is, the correct part $1 - \\mu$ times the probability $1 - \\lambda$ to be incorrect.\n",
    "\n",
    "$$\n",
    "E_{noise} = \\mu \\cdot \\lambda + (1-\\mu) \\cdot (1-\\lambda)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Following Question 1, with what value of will the performance of $h$ be independent of $\\mu$ ? Please provide explanation of your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After rearranging the above error function, we can derive the following form.\n",
    "\n",
    "$$\n",
    "E_{noise} = \\mu \\cdot \\lambda + (1-\\mu) \\cdot (1-\\lambda) \\\\\n",
    "= \\mu \\cdot (2 \\lambda -1) + 1 - \\lambda\n",
    "$$\n",
    "\n",
    "When $\\lambda = \\frac{1}{2}$, we can see that the first part becomes $0$, making $h$ independent of $\\mu$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization Error\n",
    "---\n",
    "\n",
    "Questions 3-5 are about *generalization error*, and getting the feel of the bounds numerically. Please use the simple upper bound $N^{d_{vc}}$ on the growth function $m_{H}(N)$, assuming that $N \\le 2$ and $d_{vc} \\le 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. For an $H$ with $d_{vc} = 10$, if you want 95% confidence that your generalization error is at most 0.05, what is the sample size that the VC generalization bound predicts? Please provide calculating steps of your answer, and round your answer to the closest thousand (that is, your answer should be something like 845000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vapnik-Chervonenkis (VC) bound,\n",
    "\n",
    "$$\n",
    "P[|E_{in}(h) - E_{out}(h)| > \\epsilon] \\le 4m_{H}(2N) \\cdot exp(-\\frac{1}{8} \\epsilon^{2}N)\n",
    "$$\n",
    "\n",
    "By plugging in $d_{vc} = 10 $, $\\epsilon = 0.05$, and $m_{H}(N) = N^{d_{vc}}$, we get\n",
    "\n",
    "$$\n",
    "P[|E_{in}(h) - E_{out}(h)| > 0.05] \\le  4 \\cdot (2N)^{10} \\cdot exp(-\\frac{N}{3200}) \\le \\frac{1}{20}\n",
    "$$\n",
    "\n",
    "After $\\log$ and rearranging, we get\n",
    "\n",
    "$$\n",
    "0 \\le \\frac{N}{3200} - 10 \\log(N) - \\log(80 \\cdot 1024)\n",
    "$$\n",
    "\n",
    "We can then compute $N$ by iterating $N$ until the right hand side $ \\ge 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute N numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample size that the VC generalization bound predicts is 452958\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "N = 1\n",
    "result = -1\n",
    "N_list = []\n",
    "result_list = []\n",
    "\n",
    "while result < 0:\n",
    "    y = (N / 3200) - 10 * math.log(N) - math.log(80 * 1024)\n",
    "    result = y\n",
    "    \n",
    "    N_list.append(N)\n",
    "    result_list.append(y)\n",
    "    N += 1\n",
    "    \n",
    "print('The sample size that the VC generalization bound predicts is %d' %N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x107fdd7b8>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQk5BYGISMj9f1uMSvyJdvJ7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1045afe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(N_list, result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. There are a number of bounds on the generalization error $\\epsilon$ , all holding with probability at least $1 - \\delta$. Fix $d_{vc} = 50$ and $\\delta = 0.05$ and plot these bounds as a function of $N$. Use any numerical method to calculate the (most) generalization error by the bound. Which bound is the tightest (smallest) for very large $N$, say $N = 10,000$ ? What is the generalization error calculated by the tightest bound? Note that Devroye and Parrondo & Van den Broek are implicit bounds in $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One-Dimensional Decision Stump\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class, we taught about the learning model of **“positive and negative rays”** (which is simply one-dimensional perceptron) for one-dimensional data. The model contains hypotheses of the form: \n",
    "\n",
    "$$ h_{s, \\theta} (x) = s \\cdot sign(x - \\theta). $$\n",
    "\n",
    "The model is frequently named the **“decision stump”** model and is one of the simplest learning models. As shown in class, for one-dimensional data, the VC dimension of the decision stump model is 2.\n",
    "\n",
    "In fact, the decision stump model is one of the few models that we could easily minimize $E_{in}$ for binary classification effciently by enumerating all possible thresholds. In particular, for $N$ examples, there are at most $2N$ dichotomies (see page 22 of class05 slides), and thus at most $2N$ different $E_{in}$ values. We can then easily choose the dichotomy that leads to the lowest $E_{in}$, where ties can be broken by randomly choosing among the lowest-$E_{in}$ ones. The chosen dichotomy stands for a combination of some **'spot'** (range of $\\theta$) and $s$, and commonly the median of the range is chosen as the $\\theta$ that realizes the dichotomy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you are asked to implement such an algorithm and run your program on an artificial data set. First of all, start by generating a one-dimensional data by the procedure below:\n",
    "\n",
    "- Generate $x$ by a uniform distribution in $[-1, 1]$.\n",
    "- Generate $y$ by $\\tilde{s}(x) + noise$ where $\\tilde{s}(x) = sign(x)$ and the noise flips the result with 20% probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16.  For any decision stump $h_{s,\\theta}$ with $\\theta \\in [-1, 1]$, express $E_{out}(h_{s,\\theta})$ as a function of $\\theta$ and $s$. Please provide your derivation steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error function $E_{out}(h_{s,\\theta})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\theta > 0$, then we can compute $E_{out}$ as follow,\n",
    "\n",
    "$$\n",
    "E_{out} = \\frac{(1-\\theta)}{2} [(1 - s) \\cdot 0.8 + (1 + s) \\cdot 0.2]/2  \\\\\n",
    "+ \\frac{\\theta}{2} [(1 + s) \\cdot 0.8 + (1 -s) \\cdot 0.2]/2 \\\\\n",
    "+ \\frac{1}{2} [(1 + s) \\cdot 0.8 + (1 -s) \\cdot 0.2] /2\n",
    "$$\n",
    "\n",
    "When $\\theta <0 $, then we can compute $E_{out}$ as follow,\n",
    "\n",
    "$$\n",
    "E_{out} = \\frac{1}{2} [(1 + s) \\cdot 0.8 + (1 -s) \\cdot 0.2] /2 \\\\\n",
    "+ \\frac{\\theta}{2} [(1 + s) \\cdot 0.8 + (1 -s) \\cdot 0.2]/2 \\\\\n",
    "+ \\frac{(\\theta-1)}{2} [(1 - s) \\cdot 0.8 + (1 + s) \\cdot 0.2]/2 \n",
    "$$\n",
    "\n",
    "After rearrangment, we can get the final result,\n",
    "\n",
    "$$\n",
    "E_{out} = 0.5 + 0.3 \\cdot s \\cdot (|\\theta| - 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. (`*`) Generate a data set of size 20 by the procedure above and run the one-dimensional decision stump algorithm on the data set. Record $E_{in}$ and compute $E_{out}$ with the formula above. Repeat the experiment (including data generation, running the decision stump algorithm, and computing $E_{in}$ and $E_{out}$) 5,000 times. What is the average $E_{in}$? Plot a histogram for your $E_{in}$ distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. (`*`) Continuing from the previous question, what is the average $E_{out}$? Plot a histogram for your $E_{out}$ distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def generate_data(size, low, high, prob):\n",
    "    \"\"\" Generate X by a uniform distribution in the specified range.\n",
    "        Generate Y with a given probaility of noise.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = np.random.uniform(low, high, size)\n",
    "    Y = np.sign(X)\n",
    "    \n",
    "    # noise: flip the result with specified prob\n",
    "    for i in range(len(Y)):\n",
    "        if random.random() < prob:\n",
    "            Y[i] *= -1\n",
    "            \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def decision_stump(X, Y):\n",
    "    \"\"\"Decision stump model for one-dimensional data. Return error, theta (threshold) and s.\"\"\"\n",
    "    \n",
    "    err_1 = []            # when s = 1\n",
    "    err_2 = []            # when s = -1\n",
    "    X_sort = sorted(X)\n",
    "    \n",
    "    # use median as the threshold\n",
    "    thresholds = [(X_sort[i] + X_sort[i + 1]) / 2 for i in range(len(X) - 1)]\n",
    "    # use max as the extreme case (classify all data to one side)\n",
    "    thresholds.append(X_sort[-1])\n",
    "    \n",
    "    # iterate over all thresholds and compute error\n",
    "    for threshold in thresholds:\n",
    "        theta = threshold\n",
    "        Y_pred = np.sign(X - theta)\n",
    "        err_1.append(np.sum(Y_pred != Y))      # when s = 1\n",
    "        err_2.append(np.sum(-Y_pred != Y))     # when s = -1\n",
    "    \n",
    "    # determine the best theta and s\n",
    "    if np.min(err_1) < np.min(err_2):\n",
    "        avg_err = np.min(err_1) / len(X) \n",
    "        final_theta = thresholds[np.argmin(err_1)]\n",
    "        s = 1\n",
    "    else:\n",
    "        avg_err = np.min(err_2) / len(X) \n",
    "        final_theta = thresholds[np.argmin(err_2)]\n",
    "        s = -1\n",
    "        \n",
    "    return avg_err, final_theta, s\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute $E_{out}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def err_out_function(s, theta):\n",
    "    \n",
    "    return 0.5 + 0.3 * s * (abs(theta) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample error: 0.169750\n",
      "Out-of-sample error: 0.258366\n"
     ]
    }
   ],
   "source": [
    "size = 20; low = -1; high = 1; prob = 0.2; experiment = 5000\n",
    "\n",
    "total_err_in = []\n",
    "total_err_out = []\n",
    "for i in range(experiment):\n",
    "    X, Y = generate_data(size, low, high, prob)\n",
    "    \n",
    "    err_in, theta, s = decision_stump(X, Y)\n",
    "    total_err_in.append(err_in)\n",
    "    \n",
    "    err_out = err_out_function(s, theta)\n",
    "    total_err_out.append(err_out)\n",
    "    \n",
    "    \n",
    "avg_err_in = np.mean(total_err_in)\n",
    "avg_err_out = np.mean(total_err_out)\n",
    "print('In-sample error: %f' %avg_err_in)\n",
    "print('Out-of-sample error: %f' %avg_err_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10739a0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(total_err_in, bins= 20, label= 'In-sample error')\n",
    "plt.hist(total_err_out, bins= 20, label= 'Out-of-sample error')\n",
    "plt.legend()\n",
    "plt.title('Error Distribution')\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frequency')\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Multi-dimensional Decision Stump\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision stumps can also work for multi-dimensional data. In particular, each decision stump now deals with a specific dimension $i$, as shown below. \n",
    "\n",
    "$$ h_{s, i, \\theta} (x) = s \\cdot sign(x_i - \\theta). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the following decision stump algorithm for multi-dimensional data:\n",
    "    \n",
    "1. for each dimension $i = 1, 2, ..., d$, find the best decision stump $h_{s, i, \\theta}$ using the one-dimensional decision stump algorithm that you have just implemented.\n",
    "2. return the *“best of best”* decision stump in terms of $E_{in}$. If there is a tie, please randomly choose among the lowest-$E_{in}$ ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data $D_{train}$ is available at: http://www.csie.ntu.edu.tw/~htlin/course/ml14fall/hw2/hw2_train.dat\n",
    "\n",
    "The testing data $D_{test}$ is available at: http://www.csie.ntu.edu.tw/~htlin/course/ml14fall/hw2/hw2_test.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. (`*`) Run the algorithm on the $D_{train}$. What is the optimal decision stump returned by your program? What is the $E_{in}$ of the optimal decision stump?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 (`*`) Use the returned decision stump to predict the label of each example within the $D_{test}$. Report an estimate of $E_{out}$ by $E_{test}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_data(file):\n",
    "    data = pd.read_csv(file, sep = ' ', header = None)\n",
    "    data = data.drop(0, axis = 1)  # drop the first empty column\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_decision_stump(data):\n",
    "    \n",
    "    Y = np.array(data[10])\n",
    "    err_column = []\n",
    "    theta_column = []\n",
    "    s_column = []\n",
    "    \n",
    "    for column in data.loc[:, :9]:\n",
    "        X = np.array(data[column])\n",
    "        err, theta, s = decision_stump(X, Y)\n",
    "        \n",
    "        err_column.append(err)\n",
    "        theta_column.append(theta)\n",
    "        s_column.append(s)\n",
    "    \n",
    "    best_err = np.min(err_column)\n",
    "    best_theta = theta_column[np.argmin(err_column)]\n",
    "    best_s = s_column[np.argmin(err_column)]\n",
    "    best_column = np.argmin(err_column) + 1\n",
    "    \n",
    "    return best_err, best_theta, best_s, best_column\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute $E_{out}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(X, Y, theta, s):\n",
    "\n",
    "    Y_pred = s * np.sign(X - theta)\n",
    "    err = np.sum(Y_pred != Y)\n",
    "    avg_err = err / len(Y)\n",
    "    \n",
    "    return avg_err\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err_in :  0.25\n",
      "theta  :  1.6175\n",
      "s      :  -1\n",
      "column :  4\n"
     ]
    }
   ],
   "source": [
    "train_file = 'data/hw2_train.dat.txt'\n",
    "data_train = read_data(train_file)\n",
    "err, theta, s, column = multi_decision_stump(data_train)\n",
    "\n",
    "print('err_in : ', err)\n",
    "print('theta  : ', theta)\n",
    "print('s      : ', s)\n",
    "print('column : ', column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err_out:  0.355\n"
     ]
    }
   ],
   "source": [
    "test_file = 'data/hw2_test.dat.txt'\n",
    "data_test = read_data(test_file)\n",
    "\n",
    "Y = data_test[10].values\n",
    "X = data_test[column].values\n",
    "err_out = test_model(X, Y, theta, s)\n",
    "print('err_out: ', err_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
